---
# Ergatis Component Documentation
# Extracted from source by extract_component_docs.pl
# Source: TIGR/JCVI/IGS Ergatis bioinformatics workflow system
#
# This file preserves ALL documentation, comments, parameter descriptions,
# and structural details from the original Ergatis source files.

component: backupdb
extracted_at: "2026-02-19T15:34:47"
source_files:
  - backupdb.config
  - backupdb.xml
  - workflow/backupdb-master.ini
  - workflow/backupdbconf.ini

# Configuration file - all sections, parameters, defaults, and inline comments
config:
  interface:
    classification: database / utilities
  parameters:
    USERNAME: access
    PASSWORD: access
    DATABASE: ""
    SERVER: SYBTIGR
    # Relational database management system type e.g. sybase or postgresql
    DATABASE_TYPE: sybase
    # Batchsize is a Sybase bcp utility parameter.  Irrelevant for database_type postgresql.
    BATCHSIZE: 30000
  input:
    # Here is the list of core chado tables and chado-mart materialized views that will be backed up.
    # The backup process will execute on the local machine.
    TABLE_LIST: "tableinfo,project,db,cv,cvterm,dbxrefprop,cvtermprop,pub,synonym,pubprop,pub_relationship,pub_dbxref,pubauthor,organism,organismprop,organism_dbxref,cvtermpath,cvtermsynonym,cvterm_relationship,cvterm_dbxref,feature_pub,featureprop_pub,feature_synonym,feature_cvterm,feature_cvterm_dbxref,feature_cvterm_pub,feature_cvtermprop,feature_relationship_pub,feature_relationshipprop,feature_relprop_pub,analysis,analysisprop,phylotree,phylotree_pub,phylonode,phylonode_dbxref,phylonode_pub,phylonode_organism,phylonodeprop,phylonode_relationship,cm_blast,cm_proteins,cm_clusters,cm_cluster_members"
    # Here is the list of core chado tables that typically have large data content. 
    # For this reason, the backup processes for these will execute on the grid.
    LARGE_TABLES_LIST: "dbxref,feature,featureprop,feature_dbxref,featureloc,feature_relationship,analysisfeature"
  output:
    OUTPUT_TOKEN: default
    OUTPUT_DIRECTORY: $;REPOSITORY_ROOT$;/output_repository/$;COMPONENT_NAME$;/$;PIPELINEID$;_$;OUTPUT_TOKEN$;
  component:
    COMPONENT_NAME: backupdb
    WORKFLOW_REPOSITORY: $;REPOSITORY_ROOT$;/workflow/runtime/$;COMPONENT_NAME$;/$;PIPELINEID$;_$;OUTPUT_TOKEN$;
    PIPELINE_TOKEN: unnamed
    # The version,revision,tag here is set by an interpolated CVS tag
    VERSION: 2.0
    RELEASE_TAG: $Name$
    REVISION: $Revision$
    TEMPLATE_XML: $;DOCS_DIR$;/$;COMPONENT_NAME$;.xml
    ITERATOR1: backuptables
    ITERATOR1_XML: $;DOCS_DIR$;/$;COMPONENT_NAME$;.$;ITERATOR1$;.xml
    ITERATOR2: backuplargetables
    ITERATOR2_XML: $;DOCS_DIR$;/$;COMPONENT_NAME$;.$;ITERATOR2$;.xml
    # Distributed options
    GROUP_COUNT: 1
    # no-distrib = 0 ensures that all executes in series and never parallel
    NODISTRIB: 0
    # the following keys are replaced at runtime by the invocation script
    COMPONENT_CONFIG: ""
    COMPONENT_XML: ""
    PIPELINE_XML: ""
    PIPELINEID: ""
  include:
    PROJECT_CONFIG: ""

# Main workflow XML template - step definitions
workflow_xml:
  xml_comments:
    - Preprocessing
    - Iterator1 for backing up the chado tables
    - Iterator1 for backing up the large chado tables
  command_sets:
    - backupdb workflow
  includes:
    - "file=\"$;DOCS_DIR$;/iterator_template.xml\" keys=\"$;ITERATOR_NAME$;=backuptables,$;ITERATOR_XML$;=ITERATOR1_XML,$;ITERATOR_LIST$;=$;TMP_DIR$;/chado_table.list,$;NODISTRIB$;=1\"/"
    - "file=\"$;DOCS_DIR$;/iterator_template.xml\" keys=\"$;ITERATOR_NAME$;=backuplargetables,$;ITERATOR_XML$;=ITERATOR2_XML,$;ITERATOR_LIST$;=$;TMP_DIR$;/large_chado_table.list,$;NODISTRIB$;=0\"/"
  steps:
    - name: create output directory
      type: RunUnixCommand
      executable: mkdir
      arg: -p -m 777 $;OUTPUT_DIRECTORY$;
    - name: create temp directory
      type: RunUnixCommand
      executable: mkdir
      arg: -p -m 777 $;TMP_DIR$;
    - name: Create table list for local backup process
      type: RunUnixCommand
      executable: $;BIN_DIR$;/create_table_iterator_list
      params:
        - key: --table_list
          value: $;TABLE_LIST$;
        - key: --output_iter_list
          value: $;TMP_DIR$;/chado_table.list
        - key: stdout
          value: $;TMP_DIR$;/create_table_iterator_list.pl.stdout
        - key: stderr
          value: $;TMP_DIR$;/create_table_iterator_list.pl.stderr
    - name: Create large table list for local backup process
      type: RunUnixCommand
      executable: $;BIN_DIR$;/create_table_iterator_list
      params:
        - key: --table_list
          value: $;LARGE_TABLES_LIST$;
        - key: --output_iter_list
          value: $;TMP_DIR$;/large_chado_table.list
        - key: stdout
          value: $;TMP_DIR$;/create_table_iterator_list.pl.large.stdout
        - key: stderr
          value: $;TMP_DIR$;/create_table_iterator_list.pl.large.stderr

# Workflow INI: backupdb-master.ini
workflow_ini_backupdb-master.ini:
  all_auxiliary_tables:
    # Backup all of the non-standard chado tables
    param.command: $;BIN_DIR$;/backuptables
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.auxonly: 1
    param.logfile: $;WORKFLOW_REPOSITORY$;/backuptables.pl.log
    param.outdir: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backuptables.pl.stats
    param.debug_level: 5
    param.bindir: $;BIN_DIR$;
  analysis:
    # Backup the analysis table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.analysis.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.analysis.stats
    param.abort: 1
    param.debug_level: 5
    param.table: analysis
  analysisfeature:
    # Backup the analysisfeature table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.analysisfeature.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.analysisfeature.stats
    param.abort: 1
    param.debug_level: 5
    param.table: analysisfeature
  analysisprop:
    # Backup the analysisprop table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.analysisprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.analysisprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: analysisprop
  archive_bcp_files:
    param.command: $;BIN_DIR$;/movezerofiles
    param.--dir1: $;OUTPUT_DIRECTORY$;
    param.--dir2: $;OUTPUT_DIRECTORY$;/zero
    param.--tgz: $;TGZ$;
  check_logfiles:
    param.command: $;BIN_DIR$;/check_logfiles
    param.--debug_level: 5
    param.--log4perl: $;OUTPUT_DIRECTORY$;/check_logfiles.pl.log
    param.--username: "'$;EMAIL$;'"
    param.--workflow_id: $;REPOSITORY_ROOT$;/Workflow/pipeline/$;PIPELINEID$;/pipeline.xml.instance
    param.--repository: $;WORKFLOW_REPOSITORY$;
    param.--project: $;DATABASE$;
    param.--component: $;NAME$;
  create_compute_scratch:
    # make the scratch space
    param.command: mkdir
    arg: -p -m 777 $;OUTPUT_DIRECTORY$;
  create_database_lockfile:
    # 
    # create database lock file in the repository root to traffic/prevent other
    # database manipulating workflows from accessing the same database at the same time
    param.command: $;BIN_DIR$;/gatekeeper
    param.database: $;DATABASE$;
    param.username: $;EMAIL$;
    param.component: $;NAME$;
    param.log4perl: $;WORKFLOW_REPOSITORY$;/gatekeeper.create.log
    param.action: create
    param.repository: $;REPOSITORY_ROOT$;/workflow/lock_files
    param.pipeline: $;REPOSITORY_ROOT$;/Workflow/pipeline/$;PIPELINEID$;/pipeline.xml.instance
  create_zero_scratch:
    # make the scratch space
    param.command: mkdir
    arg: -p -m 777 $;OUTPUT_DIRECTORY$;/zero
  cv:
    # Backup the db table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cv.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cv.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cv
  cvterm:
    # Backup the db table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cvterm.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cvterm.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cvterm
  cvterm_dbxref:
    # Backup the featureprop_pub table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cvterm_dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cvterm_dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cvterm_dbxref
  cvterm_relationship:
    # Backup the feature_synonym table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cvterm_relationship.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cvterm_relationship.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cvterm_relationship
  cvtermpath:
    # Backup the featureprop table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cvtermpath.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cvtermpath.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cvtermpath
  cvtermprop:
    # Backup the cvterm table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cvtermprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cvtermprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cvtermprop
  cvtermsynonym:
    # Backup the feature_pub table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.cvtermsynonym.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.cvtermsynonym.stats
    param.abort: 1
    param.debug_level: 5
    param.table: cvtermsynonym
  db:
    # Backup the db table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.db.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.db.stats
    param.abort: 1
    param.debug_level: 5
    param.table: db
  dbxref:
    # Backup the dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: dbxref
  dbxrefprop:
    # Backup the cv table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.dbxrefprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.dbxrefprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: dbxrefprop
  empty:
  feature:
    # Backup the project table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature
  feature_cvterm:
    # Backup the synonym table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_cvterm.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_cvterm.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_cvterm
  feature_cvterm_dbxref:
    # Backup the feature_cvterm_dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_cvterm_dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_cvterm_dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_cvterm_dbxref
  feature_cvterm_pub:
    # Backup the synonym table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_cvterm_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_cvterm_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_cvterm_pub
  feature_cvtermprop:
    # Backup the tableinfo table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_cvtermprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_cvtermprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_cvtermprop
  feature_dbxref:
    # Backup the feature_dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_dbxref
  feature_pub:
    # Backup the pub_dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_pub
  feature_relationship:
    # Backup the feature_relationship table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_relationship.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_relationship.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_relationship
  feature_relationship_pub:
    # Backup the feature_relationship table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_relationship_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_relationship_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_relationship_pub
  feature_relationshipprop:
    # Backup the feature_relationship table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_relationshipprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_relationshipprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_relationshipprop
  feature_relprop_pub:
    # Backup the feature_relationship table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_relprop_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_relprop_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_relprop_pub
  feature_synonym:
    # Backup the pubprop table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.feature_synonym.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.feature_synonym.stats
    param.abort: 1
    param.debug_level: 5
    param.table: feature_synonym
  featureloc:
    # Backup the featureloc table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.featureloc.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.featureloc.stats
    param.abort: 1
    param.debug_level: 5
    param.table: featureloc
  featureprop:
    # Backup the pub_author table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.featureprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.featureprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: featureprop
  featureprop_pub:
    # Backup the pub_relationship table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.featureprop_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.featureprop_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: featureprop_pub
  generate_directory_list:
    param.command: find
    arg: $;OUTPUT_DIRECTORY$;
    arg: -type d -mindepth 1
    param.stdout: $;OUTPUT_DIRECTORY$;/directories.list
  gzip_analysis:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/analysis.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_analysis.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_analysis.stderr
  gzip_analysisfeature:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/analysisfeature.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_analysisfeature.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_analysisfeature.stderr
  gzip_analysisprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/analysisprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_analysisprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_analysisprop.stderr
  gzip_cv:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cv.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cv.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cv.stderr
  gzip_cvterm:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cvterm.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cvterm.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cvterm.stderr
  gzip_cvterm_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cvterm_dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cvterm_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cvterm_dbxref.stderr
  gzip_cvterm_relationship:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cvterm_relationship.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cvterm_relationship.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cvterm_relationship.stderr
  gzip_cvtermpath:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cvtermpath.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cvtermpath.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cvtermpath.stderr
  gzip_cvtermprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cvtermprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cvtermprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cvtermprop.stderr
  gzip_cvtermsynonym:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/cvtermsynonym.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_cvtermsynonym.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_cvtermsynonym.stderr
  gzip_db:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/db.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_db.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_db.stderr
  gzip_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_dbxref.stderr
  gzip_dbxrefprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/dbxrefprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_dbxrefprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_dbxrefprop.stderr
  gzip_feature:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature.stderr
  gzip_feature_cvterm:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_cvterm.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvterm.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvterm.stderr
  gzip_feature_cvterm_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_cvterm_dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvterm_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvterm_dbxref.stderr
  gzip_feature_cvterm_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_cvterm_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvterm_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvterm_pub.stderr
  gzip_feature_cvtermprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_cvtermprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvtermprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_cvtermprop.stderr
  gzip_feature_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_dbxref.stderr
  gzip_feature_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_pub.stderr
  gzip_feature_relationship:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_relationship.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_relationship.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_relationship.stderr
  gzip_feature_relationship_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_relationship_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_relationship_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_relationship_pub.stderr
  gzip_feature_relationshipprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_relationshipprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_relationshipprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_relationshipprop.stderr
  gzip_feature_relprop_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_relprop_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_relprop_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_relprop_pub.stderr
  gzip_feature_synonym:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/feature_synonym.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_feature_synonym.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_feature_synonym.stderr
  gzip_featureloc:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/featureloc.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_featureloc.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_featureloc.stderr
  gzip_featureprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/featureprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_featureprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_featureprop.stderr
  gzip_featureprop_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/featureprop_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_featureprop_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_featureprop_pub.stderr
  gzip_organism:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/organism.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_organism.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_organism.stderr
  gzip_organism_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/organism_dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_organism_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_organism_dbxref.stderr
  gzip_organismprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/organismprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_organismprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_organismprop.stderr
  gzip_phylonode:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylonode.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylonode.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylonode.stderr
  gzip_phylonode_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylonode_dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_dbxref.stderr
  gzip_phylonode_organism:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylonode_organism.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_organism.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_organism.stderr
  gzip_phylonode_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylonode_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_pub.stderr
  gzip_phylonode_relationship:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylonode_relationship.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_relationship.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylonode_relationship.stderr
  gzip_phylonodeprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylonodeprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylonodeprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylonodeprop.stderr
  gzip_phylotree:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylotree.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylotree.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylotree.stderr
  gzip_phylotree_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/phylotree_pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_phylotree_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_phylotree_pub.stderr
  gzip_project:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/project.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_project.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_project.stderr
  gzip_pub:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/pub.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_pub.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_pub.stderr
  gzip_pub_dbxref:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/pub_dbxref.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_pub_dbxref.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_pub_dbxref.stderr
  gzip_pub_relationship:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/pub_relationship.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_pub_relationship.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_pub_relationship.stderr
  gzip_pubauthor:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/pubauthor.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_pubauthor.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_pubauthor.stderr
  gzip_pubprop:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/pubprop.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_pubprop.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_pubprop.stderr
  gzip_synonym:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/synonym.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_synonym.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_synonym.stderr
  gzip_tableinfo:
    # 
    param.command: /usr/bin/gzip
    arg: $;OUTPUT_DIRECTORY$;/tableinfo.out
    param.stdout: $;WORKFLOW_REPOSITORY$;/gzip_tableinfo.stdout
    param.stderr: $;WORKFLOW_REPOSITORY$;/gzip_tableinfo.stderr
  organism:
    # Backup the cvterm_dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.organism.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.organism.stats
    param.abort: 1
    param.debug_level: 5
    param.table: organism
  organism_dbxref:
    # Backup the feature_cvterm table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.organism_dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.organism_dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: organism_dbxref
  organismprop:
    # Backup the feature table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.organismprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.organismprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: organismprop
  phylonode:
    # Backup the phylonode table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylonode.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylonode.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylonode
  phylonode_dbxref:
    # Backup the phylonode_dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylonode_dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylonode_dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylonode_dbxref
  phylonode_organism:
    # Backup the phylonode_organism table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylonode_organism.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylonode_organism.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylonode_organism
  phylonode_pub:
    # Backup the phylonode_pub table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylonode_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylonode_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylonode_pub
  phylonode_relationship:
    # Backup the phylonode_relationship table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylonode_relationship.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylonode_relationship.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylonode_relationship
  phylonodeprop:
    # Backup the phylonodeprop table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylonodeprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylonodeprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylonodeprop
  phylotree:
    # Backup the phylotree table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylotree.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylotree.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylotree
  phylotree_pub:
    # Backup the phylotree_pub table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.phylotree_pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.phylotree_pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: phylotree_pub
  project:
    # Backup the contact table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.project.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.project.stats
    param.abort: 1
    param.debug_level: 5
    param.table: project
  pub:
    # Backup the cvtermpath table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.pub.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.pub.stats
    param.abort: 1
    param.debug_level: 5
    param.table: pub
  pub_dbxref:
    # Backup the organismprop table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.pub_dbxref.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.pub_dbxref.stats
    param.abort: 1
    param.debug_level: 5
    param.table: pub_dbxref
  pub_relationship:
    # Backup the organism table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.pub_relationship.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.pub_relationship.stats
    param.abort: 1
    param.debug_level: 5
    param.table: pub_relationship
  pubauthor:
    # Backup the organism_dbxref table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.pub_author.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.pub_author.stats
    param.abort: 1
    param.debug_level: 5
    param.table: pubauthor
  pubprop:
    # Backup the pub table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.pubprop.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.pubprop.stats
    param.abort: 1
    param.debug_level: 5
    param.table: pubprop
  remove_database_lockfile:
    # 
    # remove database lock file from the repository root which was to traffic/prevent other
    # database manipulating workflows from accessing the same database at the same time
    param.command: $;BIN_DIR$;/gatekeeper
    param.database: $;DATABASE$;
    param.username: $;EMAIL$;
    param.component: $;NAME$;
    param.log4perl: $;WORKFLOW_REPOSITORY$;/gatekeeper.remove.log
    param.action: remove
    param.repository: $;REPOSITORY_ROOT$;/workflow/lock_files
    param.pipeline: $;REPOSITORY_ROOT$;/Workflow/pipeline/$;PIPELINEID$;/pipeline.xml.instance
  synonym:
    # Backup the cvtermsynonym table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.synonym.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.synonym.stats
    param.abort: 1
    param.debug_level: 5
    param.table: synonym
  tableinfo:
    # Backup the contact table to .out bcp file
    param.command: $;BIN_DIR$;/chadoloader
    param.username: chado_admin
    param.password: chado_admin99
    param.database: $;DATABASE$;
    param.server: $;SERVER$;
    param.bcpmode: out
    param.batchsize: 10000000
    param.logfile: $;WORKFLOW_REPOSITORY$;/backup.tableinfo.log
    param.directory: $;OUTPUT_DIRECTORY$;
    param.stdout: $;WORKFLOW_REPOSITORY$;/backup.tableinfo.stats
    param.abort: 1
    param.debug_level: 5
    param.table: tableinfo

# Workflow INI: backupdbconf.ini
workflow_ini_backupdbconf.ini:
  _header:
    # configuration file for the backupdb workflow
  include backupdb:
    $;SHARED_CONFIG$;: ""
  input backupdb:
  output backupdb:
    $;OUTPUT_TOKEN$;: default
    $;OUTPUT_DIRECTORY$;: $;REPOSITORY_ROOT$;/output_repository/$;NAME$;/$;PIPELINEID$;_$;OUTPUT_TOKEN$;
  parameters backupdb:
    $;EMAIL$;: ""
    $;SERVER$;: ""
    $;TGZ$;: 1
  workflowdocs backupdb:
    # The version here is set by an interpolated CVS tag
    $;VERSION$;: $Name$
    $;REVISION$;: $Revision$
    $;TAG$;: $Name$
    $;NAME$;: backupdb
    $;MASTER_TEMPLATE_INI$;: $;WORKFLOWDOCS_DIR$;/backupdb-master.ini
    $;MASTER_TEMPLATE_XML$;: $;WORKFLOWDOCS_DIR$;/backupdb-master_template.xml
    $;WORKFLOW_REPOSITORY$;: $;REPOSITORY_ROOT$;/Workflow/$;NAME$;/$;PIPELINEID$;_$;OUTPUT_TOKEN$;
    $;GROUP_COUNT$;: 400
    # the following keys are replaced at runtime by the invocation script
    $;COMPONENT_CONFIG$;: ""
    $;NODISTRIB$;: 0

# Perl script documentation (POD)
perl_scripts:
  - script: create_table_iterator_list.pl
    pod: |
  =head1  NAME 
  
  create_table_iterator_list.pl - 
  
  =head1 SYNOPSIS
  
  USAGE:  create_table_iterator_list
  
  =head1 OPTIONS
  
  =item *
  
  B<--debug,-d> Debug level.  Use a large number to turn on verbose debugging. 
  
  =item *
  
  B<--log,-l> Log file
  
  =item *
  
  B<--help,-h> This help message
  
  =head1   DESCRIPTION
